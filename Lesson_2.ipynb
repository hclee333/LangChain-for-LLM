{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd1b5336",
   "metadata": {},
   "source": [
    "# LangChain for LLM Application Development from DeepLearning.AI\n",
    "## Lesson 2: Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0f40549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environ({'TMPDIR': '/var/folders/9k/956xnzkj6gj30_bckgwcyl3m0000gn/T/', '__CFBundleIdentifier': 'com.apple.Terminal', 'XPC_FLAGS': '0x0', 'LaunchInstanceID': '7DB4FF6D-56CE-42BE-86CD-6F2D0ABEAB5B', 'TERM': 'xterm-color', 'SSH_AUTH_SOCK': '/private/tmp/com.apple.launchd.WPQ4qewqks/Listeners', 'SECURITYSESSIONID': '18e05', 'XPC_SERVICE_NAME': '0', 'TERM_PROGRAM': 'Apple_Terminal', 'TERM_PROGRAM_VERSION': '454.1', 'TERM_SESSION_ID': 'ADB6D160-EB67-4962-A917-D59C584AE1F4', 'SHELL': '/bin/zsh', 'HOME': '/Users/hclee', 'LOGNAME': 'hclee', 'USER': 'hclee', 'PATH': '/opt/anaconda3/bin:/opt/anaconda3/condabin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin', 'SHLVL': '1', 'PWD': '/Users/hclee', 'OLDPWD': '/Users/hclee', 'CONDA_EXE': '/opt/anaconda3/bin/conda', '_CE_M': '', '_CE_CONDA': '', 'CONDA_PYTHON_EXE': '/opt/anaconda3/bin/python', 'CONDA_SHLVL': '1', 'CONDA_PREFIX': '/opt/anaconda3', 'CONDA_DEFAULT_ENV': 'base', 'CONDA_PROMPT_MODIFIER': '(base) ', 'LC_CTYPE': 'UTF-8', '_': '/opt/anaconda3/bin/jupyter', 'JPY_PARENT_PID': '3269', 'CLICOLOR': '1', 'PAGER': 'cat', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://ipykernel.pylab.backend_inline', 'OPENAI_API_KEY': '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'})\n",
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv('OPENAI_API_KEY.env')  # Load the specified .env file\n",
    "print(os.environ)  # Print all environment variables\n",
    "print(os.environ.get('OPENAI_API_KEY'))  # Check specifically for your key\n",
    "\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']  # Access your API key\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b56bc490",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92546f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# account for deprecation of LLM model\n",
    "import datetime\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# Set the model variable based on the current date\n",
    "if current_date > target_date:\n",
    "    llm_model = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    llm_model = \"gpt-3.5-turbo-0301\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "465106b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0, model=llm_model)\n",
    "# creates memory buffer to record history of chat\n",
    "memory = ConversationBufferMemory()\n",
    "# creates langchain\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bb150b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Howard\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Howard! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Howard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b305cb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Howard\n",
      "AI: Hello Howard! It's nice to meet you. How can I assist you today?\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Howard.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "610b4e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Howard\n",
      "AI: Hello Howard! It's nice to meet you. How can I assist you today?\n",
      "Human: What is my name?\n",
      "AI: Your name is Howard.\n",
      "Human: What is your name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I am an AI assistant, so I don't have a personal name like humans do. You can just call me AI or assistant.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28b0ea64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, my name is Howard\n",
      "AI: Hello Howard! It's nice to meet you. How can I assist you today?\n",
      "Human: What is my name?\n",
      "AI: Your name is Howard.\n",
      "Human: What is your name?\n",
      "AI: I am an AI assistant, so I don't have a personal name like humans do. You can just call me AI or assistant.\n"
     ]
    }
   ],
   "source": [
    "# stores entire conversation in memory buffer\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26fbc054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi, my name is Howard\\nAI: Hello Howard! It's nice to meet you. How can I assist you today?\\nHuman: What is my name?\\nAI: Your name is Howard.\\nHuman: What is your name?\\nAI: I am an AI assistant, so I don't have a personal name like humans do. You can just call me AI or assistant.\"}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can also retrieve using function load_memory_variables in the format of dict {}, key 'history'\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae53c167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can also use Class ConversationBufferMemory to store only the context\n",
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce1dc15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"}, \n",
    "                    {\"output\": \"What's up\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7567aef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi\n",
      "AI: What's up\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d9d8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
